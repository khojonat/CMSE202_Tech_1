{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e1ba6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between a train and test sets \n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.initializers import RandomNormal\n",
    "import tensorflow\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "feature_vector_length = 784\n",
    "num_classes = 10 #reshaped to 28x28 pixels= 784 because cant be on 2d\n",
    "'''\n",
    "One MNIST sample is an image of 28 by 28 pixels.\n",
    "MNIST dataset contains 60.000 images in its training set. Each image belongs to one of ten classes\n",
    "\n",
    "'''\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "#reshaping the data from 2d-->1d\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_vector_length)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_vector_length)\n",
    "\n",
    "#X elements=feature vectors \n",
    "#Y elements=targets (0-9).\n",
    "\n",
    "\n",
    "'''\n",
    "converting to grey scale in order to add new colors\n",
    "\n",
    "'''\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Convert target classes to categorical ones\n",
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29ef4dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (feature_vector_length,)\n",
    "print(f'Feature shape: {input_shape}')\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(350, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "784ac96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "192/192 [==============================] - 12s 62ms/step - loss: 0.6914 - accuracy: 0.7983 - val_loss: 0.1686 - val_accuracy: 0.9506\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 8s 43ms/step - loss: 0.1570 - accuracy: 0.9536 - val_loss: 0.1249 - val_accuracy: 0.9638\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 9s 49ms/step - loss: 0.1019 - accuracy: 0.9707 - val_loss: 0.1035 - val_accuracy: 0.9696\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 16s 83ms/step - loss: 0.0708 - accuracy: 0.9794 - val_loss: 0.1007 - val_accuracy: 0.9706\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 0.0547 - accuracy: 0.9840 - val_loss: 0.0890 - val_accuracy: 0.9743\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 11s 58ms/step - loss: 0.0391 - accuracy: 0.9888 - val_loss: 0.0845 - val_accuracy: 0.9737\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 8s 42ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 0.0852 - val_accuracy: 0.9748\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 8s 42ms/step - loss: 0.0218 - accuracy: 0.9948 - val_loss: 0.0775 - val_accuracy: 0.9775\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 10s 50ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.0802 - val_accuracy: 0.9764\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 11s 57ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.0805 - val_accuracy: 0.9782\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0760 - accuracy: 0.9785\n",
      "Test results - Loss: 0.07600464671850204 - Accuracy: 0.9785000085830688%\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "model = Sequential()\n",
    "model.add(Dense(350, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Configure the model and start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=250, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE: https://medium.com/analytics-vidhya/multi-layer-perceptron-using-keras-on-mnist-dataset-for-digit-classification-problem-relu-a276cbf05e97\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
